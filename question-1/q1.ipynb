{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the cats and dogs well separated, i.e. can you obtain good classification test accuracy performance on this data set? Compare at least 3 classifiers.\n",
    "\n",
    "Are there any images that are consistently mislabeled by the classifiers (use resampling to ascertain)? Why do you think these are difficult images to classify? Do the classifiers struggle with the same observations?\n",
    "\n",
    "Are the errors balanced or is one class more difficult to classify correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate, cross_val_predict\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def read_data_file(filename: str) -> pd.DataFrame:\n",
    "    path = Path(os.getcwd() + 'q1.ipynb')\n",
    "    data_folder = str(path.parent.absolute()) + '/data/'\n",
    "    return pd.read_csv(data_folder + filename)\n",
    "\n",
    "\n",
    "features = read_data_file('CATSnDOGS.csv') / 255 # Rescale features to values between 0 and 1\n",
    "labels = read_data_file('Labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fit_time  score_time  test_accuracy  test_precision  test_recall  \\\n",
      "0   0.151121    0.046213       0.823529        0.777778        0.875   \n",
      "1   0.118792    0.049701       0.823529        0.857143        0.750   \n",
      "2   0.129698    0.043484       0.705882        1.000000        0.375   \n",
      "3   0.114759    0.052727       0.941176        1.000000        0.875   \n",
      "4   0.117213    0.042294       0.812500        0.857143        0.750   \n",
      "5   0.092210    0.044382       0.625000        1.000000        0.250   \n",
      "6   0.112166    0.049823       0.625000        0.666667        0.500   \n",
      "7   0.101025    0.045671       0.937500        1.000000        0.875   \n",
      "8   0.137376    0.044211       0.937500        0.888889        1.000   \n",
      "9   0.465667    0.026216       0.764706        0.700000        0.875   \n",
      "10  0.472822    0.027593       0.764706        0.750000        0.750   \n",
      "11  0.424196    0.034567       0.529412        0.500000        0.375   \n",
      "12  0.484139    0.037761       0.941176        0.888889        1.000   \n",
      "13  0.485015    0.025845       0.687500        0.714286        0.625   \n",
      "14  0.533168    0.027638       0.625000        0.750000        0.375   \n",
      "15  0.505296    0.028639       0.625000        0.625000        0.625   \n",
      "16  0.567452    0.033484       0.812500        0.777778        0.875   \n",
      "17  0.442524    0.033705       0.750000        0.700000        0.875   \n",
      "18  0.437655    0.040918       0.764706        0.700000        0.875   \n",
      "19  0.394500    0.040420       0.764706        0.750000        0.750   \n",
      "20  0.383575    0.041571       0.882353        0.875000        0.875   \n",
      "21  0.389719    0.042525       0.882353        0.875000        0.875   \n",
      "22  0.386277    0.040240       0.687500        0.714286        0.625   \n",
      "23  0.388779    0.039953       0.625000        0.750000        0.375   \n",
      "24  0.384612    0.041261       0.687500        0.714286        0.625   \n",
      "25  0.389478    0.042341       0.812500        0.857143        0.750   \n",
      "26  0.399758    0.039853       0.875000        0.800000        1.000   \n",
      "\n",
      "     test_f1   model  \n",
      "0   0.823529     SVM  \n",
      "1   0.800000     SVM  \n",
      "2   0.545455     SVM  \n",
      "3   0.933333     SVM  \n",
      "4   0.800000     SVM  \n",
      "5   0.400000     SVM  \n",
      "6   0.571429     SVM  \n",
      "7   0.933333     SVM  \n",
      "8   0.941176     SVM  \n",
      "9   0.777778  LogReg  \n",
      "10  0.750000  LogReg  \n",
      "11  0.428571  LogReg  \n",
      "12  0.941176  LogReg  \n",
      "13  0.666667  LogReg  \n",
      "14  0.500000  LogReg  \n",
      "15  0.625000  LogReg  \n",
      "16  0.823529  LogReg  \n",
      "17  0.777778  LogReg  \n",
      "18  0.777778      RF  \n",
      "19  0.750000      RF  \n",
      "20  0.875000      RF  \n",
      "21  0.875000      RF  \n",
      "22  0.666667      RF  \n",
      "23  0.500000      RF  \n",
      "24  0.666667      RF  \n",
      "25  0.800000      RF  \n",
      "26  0.888889      RF  \n"
     ]
    }
   ],
   "source": [
    "def compare_ensemble(models: list(), features: pd.DataFrame, labels: pd.DataFrame) -> pd.DataFrame:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.25, random_state=42)\n",
    "    dfs = []\n",
    "    scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    target_names = ['cat', 'dog']\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = StratifiedKFold(n_splits=9, shuffle=True, random_state=42)\n",
    "        cv_results = cross_validate(model, X_train, y_train.to_numpy().ravel(), cv=kfold, scoring=scoring)\n",
    "        clf = model.fit(X_train, y_train.to_numpy().ravel())\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        print(name)\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "        df = pd.DataFrame(cv_results)\n",
    "        df['model'] = name\n",
    "        dfs.append(df)\n",
    "\n",
    "    result = pd.concat(dfs, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Fix so that LogisticRegression is used with optimal parameter? Any other settings to improve SVC, RandomForest?\n",
    "models = [\n",
    "          ('SVM', SVC()),\n",
    "          ('LogReg', LogisticRegression(max_iter=1000)), \n",
    "          ('RF', RandomForestClassifier())\n",
    "        ]\n",
    "\n",
    "results = compare_ensemble(models, features, labels)\n",
    "#print(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8230433a90deedfd204f402afa77435b9f1612df21a8fe919bc9fb2fb8e7ebcb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dat405')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
